---
title: "Vignette"
author: "Shijia Zhang"
date: "2024-08-28"
output: html_document
---

```{r}
library(devtools)
install_github("Shijia1997/ADMerge",force = TRUE)

library(ADMerge)
# library(dplyr)
library(knitr)
# library(readxl)
library(kableExtra)

```

# updated

```{r}
library(ADMerge)
library(dplyr)
BIOCARD_table =get_src_table(path = "BIOCARD Demonstration",
              ID_usr_list = c("SUBJECT_ID"),
              DATE_usr_list = c("VISITDATE","DIAGDATE","date"),
              IS_overlap_list = c("FALSE"),
              WINDOW_list = c(366))

plot_files(path = "BIOCARD Demonstration", dict_src = BIOCARD_table, study_type = "BIOCARD",date_type = "Date") 

Biocard_merged = ad_merge(path = "BIOCARD Demonstration",DATE_type = "Date",timeline_file = "BIOCARD_DiagnosisData_2021.11.01",dict_src = BIOCARD_table)

complete_output = review_complete(Biocard_merged,check_cols = c("C1204A","C1204B","DIAGNOSIS","DOB","RACE","AB40","AB42"))

data = complete_output$complete_df

complete_output$plot

data = data %>% mutate(cognitive_impairment_conditions = case_when(DIAGNOSIS == "NORMAL" ~0,
                                                                   TRUE ~ 1))
# Prepare the data
# Ensure Date columns are in Date format at the outset
cox_df <- data %>%
  group_by(ID_merged) %>%
  summarize(
    # Use if_else to preserve Date type for first_impairment_date
    first_impairment_date = if_else(
      any(cognitive_impairment_conditions == 1),
      min(Date_timeline[cognitive_impairment_conditions == 1], na.rm = TRUE),
      as.Date(NA)  # Ensure NA is treated as Date type
    ),
    # Calculate last visit date and baseline date
    last_visit_date = max(Date_timeline, na.rm = TRUE),
    baseline_date = min(Date_timeline, na.rm = TRUE),
    # Define event as 1 if any impairment was observed
    event = if_else(any(cognitive_impairment_conditions == 1), 1, 0),
    # Retrieve additional columns from the first encounter
    C1204A = C1204A[which.min(Date_timeline)],
    C1204B = C1204B[which.min(Date_timeline)],
    RACE = RACE[which.min(Date_timeline)],
    AB40 = AB40[which.min(Date_timeline)],
    AB42 = AB42[which.min(Date_timeline)]
  ) %>%
  mutate(
    # Define tstart as 0 and tstop based on event status
    tstart = 0,
    tstop = if_else(
      event == 1,
      as.numeric((first_impairment_date - baseline_date) / 365.25),  # Time to event
      as.numeric((last_visit_date - baseline_date) / 365.25)  # Time to censoring
    )
  ) %>%
  # Retain rows where tstop is not zero and select required columns
  filter(tstop != 0) %>%
  select(ID_merged, tstart, tstop, event, C1204A, C1204B, RACE, AB40,AB42)


cox_df$event <- as.factor(cox_df$event)
cox_df$event <- droplevels(factor(cox_df$event, levels = c(0, 1)))


library(DMwR)
# Ensure the dataset has no unused levels and is formatted properly
cox_df <- droplevels(cox_df)

cox_df <- as.data.frame(cox_df)

cox_df <- cox_df %>% select(-c(ID_merged))



# Applying SMOTE on `event` column
smoted_data <- SMOTE(event ~ ., data = cox_df, perc.over = 2000, perc.under = 150)

library(survival)
library(caret)

# Set a seed for reproducibility
set.seed(123)

# Split data into training (80%) and testing (20%) sets
train_index <- createDataPartition(smoted_data$event, p = 0.8, list = FALSE)
train_data <- smoted_data[train_index, ]
test_data <- smoted_data[-train_index, ]

train_data$time = train_data$tstop
test_data$time = test_data$tstop

train_data <- train_data %>% select(-tstart)
test_data <- test_data %>% select(-tstart)

train_data$event <- as.numeric(as.character(train_data$event))
test_data$event <- as.numeric(as.character(test_data$event))


cox_model <- coxph(Surv(time, event) ~ C1204A + C1204B + RACE + AB40 + AB42, data = train_data)

test_data$risk_score <- predict(cox_model, newdata = test_data, type = "risk")


cox_model %>% gtsummary::tbl_regression(exp =TRUE)


colnames(BIOCARD_table)

```

```{r}
library(dplyr)
library(ggplot2)

# 假设 complete_df 已经准备好了
num_vars <- c("ptau181", "ttau", "AB42", "AB40", "AB42AB40", 
              "mattis", "LogMem1_B", "LogMem2_B", "BNTPCT", 
              "DECAGE", "EDUC")

dat <- complete_df %>% select(all_of(num_vars)) %>%
  select(where(is.numeric)) # 只保留数值型

dat

# 去除全NA、全常数
valid_vars <- sapply(dat, function(x) !all(is.na(x)) && length(unique(na.omit(x))) > 1)
dat_clean <- dat[, valid_vars]

# 如果没变量就要重选
if(ncol(dat_clean) == 0) stop("没有可用于PCA的变量，请重新挑选。")

# 做PCA
pca <- prcomp(dat_clean, center = TRUE, scale. = TRUE)
pca_df <- as.data.frame(pca$x[, 1:2])
pca_df$DIAGNOSIS <- complete_df$DIAGNOSIS

# 画图
ggplot(pca_df, aes(x = PC1, y = PC2, color = DIAGNOSIS)) +
  geom_point(alpha = 0.8, size = 2) +
  theme_minimal() +
  labs(title = "PCA (Key Quantitative Variables)", x = "PC1", y = "PC2", color = "Diagnosis")

```

```{r}
# 1. 选择聚类变量（如上）
check_vars <- c(
  "SEX", "RACE", "HISPANIC", "EDUC",
  "C1201D", "C1204A", "C1204B", "C1205A", "C1205B", "C1208A",
  "C1A106", "C1A107", "C1A108", "BNTPCT", "mattis", "LogMem1_B", "LogMem2_B",
  "ptau181", "ttau", "AB42", "AB40", "AB42AB40"
)

# 2. 挑出有这些变量且无缺失的样本
review_res <- review_complete(Biocard_merged, check_cols = check_vars)
complete_df <- review_res$complete_df

cat("可用于聚类的样本量:", nrow(complete_df), "\n")

if (nrow(complete_df) < 10) {
  stop("完整病例太少，建议减少变量数量或允许部分缺失。")
}

# 3. 筛选numeric型变量 + 性别/民族 (转化为factor或numeric)
dat <- complete_df[, check_vars]

# 性别、民族转 numeric
to_numeric <- function(x) {
  if (is.factor(x)) as.numeric(x) else if (is.character(x)) as.numeric(as.factor(x)) else x
}
for (v in c("SEX", "RACE", "HISPANIC")) {
  if (v %in% names(dat)) dat[[v]] <- to_numeric(dat[[v]])
}

# 只保留numeric型
dat_num <- dat[, sapply(dat, is.numeric)]

# 4. 标准化
dat_scaled <- scale(dat_num)

# 5. PCA
pca <- prcomp(dat_scaled, center = TRUE, scale. = TRUE)
pca_df <- as.data.frame(pca$x[, 1:2])

# 6. 聚类（Kmeans）
set.seed(42)
km <- kmeans(dat_scaled, centers = 3)
pca_df$cluster <- factor(km$cluster)

# 7. 可视化（可选加诊断类别）
if ("DIAGNOSIS" %in% names(complete_df)) {
  pca_df$DIAGNOSIS <- complete_df$DIAGNOSIS
  gg <- ggplot(pca_df, aes(x = PC1, y = PC2, color = DIAGNOSIS, shape = cluster)) +
    geom_point(alpha = 0.8, size = 2) +
    theme_minimal() +
    labs(title = "PCA+Kmeans clustering with Diagnosis", x = "PC1", y = "PC2", color = "Diagnosis")
} else {
  gg <- ggplot(pca_df, aes(x = PC1, y = PC2, color = cluster)) +
    geom_point(alpha = 0.8, size = 2) +
    theme_minimal() +
    labs(title = "PCA+Kmeans clustering", x = "PC1", y = "PC2")
}

print(gg)

```
```{r}
library(tidyverse)
library(Rtsne)
library(ggplot2)
library(RColorBrewer)

# 1. 变量清单
check_vars <- c(
  "SEX", "RACE", "HISPANIC", "EDUC",
  "C1201D", "C1204A", "C1204B", "C1205A", "C1205B", "C1208A",
  "C1A106", "C1A107", "C1A108", "BNTPCT", "mattis"
)

# 2. 获取完整病例
review_res <- review_complete(Biocard_merged, check_cols = check_vars)
complete_df <- review_res$complete_df
cat("可用于聚类的样本量:", nrow(complete_df), "\n")

if (nrow(complete_df) < 10) stop("完整病例太少，建议减少变量数量或允许部分缺失。")

# 3. 分类变量转为 numeric
dat <- complete_df[, check_vars]
cat_to_numeric <- function(x) {
  if (is.factor(x)) as.numeric(x)
  else if (is.character(x)) as.numeric(as.factor(x))
  else x
}
for (v in c("SEX", "RACE", "HISPANIC")) {
  if (v %in% names(dat)) dat[[v]] <- cat_to_numeric(dat[[v]])
}
dat_num <- dat[, sapply(dat, is.numeric)]
dat_scaled <- scale(dat_num)

# 4. tSNE降维
set.seed(42)
tsne_out <- Rtsne(as.matrix(dat_scaled), dims = 2, perplexity = 30, verbose = TRUE, max_iter = 1000)

# 5. KMeans聚类
k <- 3
kmeans_res <- kmeans(tsne_out$Y, centers = k, nstart = 20)
clusters <- as.factor(kmeans_res$cluster)

# 6. 可视化
tsne_df <- data.frame(
  tSNE1 = tsne_out$Y[, 1],
  tSNE2 = tsne_out$Y[, 2],
  Cluster = clusters,
  DIAGNOSIS = if ("DIAGNOSIS" %in% names(complete_df)) complete_df$DIAGNOSIS else NA
)

ggplot(tsne_df, aes(x = tSNE1, y = tSNE2, color = Cluster)) +
  geom_point(size = 2, alpha = 0.7) +
  scale_color_brewer(palette = "Set2") +
  theme_minimal(base_size = 14) +
  labs(title = "tSNE + KMeans Cluster on Complete Cases", color = "Cluster")

# 7. 聚类与诊断分布
if ("DIAGNOSIS" %in% names(complete_df)) {
  table_res <- table(Cluster = clusters, Diagnosis = complete_df$DIAGNOSIS)
  print(table_res)
}

# 8. 可选：聚类中心热图
library(pheatmap)
centers <- aggregate(dat_scaled, by = list(Cluster = clusters), mean)
row.names(centers) <- paste0("Cluster", centers$Cluster)
centers <- centers[, -1]
pheatmap(
  as.matrix(centers),
  cluster_cols = TRUE,
  cluster_rows = FALSE,
  color = colorRampPalette(rev(brewer.pal(7, "RdYlBu")))(100),
  main = "Cluster Centers (Feature Z-scores)",
  fontsize_row = 12
)



```
```{r}

library(tidyverse)
library(Rtsne)
library(ggplot2)
library(RColorBrewer)

# 1. 变量清单
check_vars <- c(
  "SEX", "RACE", "HISPANIC", "EDUC",
  "C1201D", "C1204A", "C1204B", "C1205A", "C1205B", "C1208A",
  "C1A106", "C1A107", "C1A108", "BNTPCT", "mattis"
)

# 2. 获取完整病例
review_res <- review_complete(Biocard_merged, check_cols = check_vars)
complete_df <- review_res$complete_df
cat("可用于聚类的样本量:", nrow(complete_df), "\n")

if (nrow(complete_df) < 10) stop("完整病例太少，建议减少变量数量或允许部分缺失。")

# 3. 分类变量转为 numeric
dat <- complete_df[, check_vars]
cat_to_numeric <- function(x) {
  if (is.factor(x)) as.numeric(x)
  else if (is.character(x)) as.numeric(as.factor(x))
  else x
}
for (v in c("SEX", "RACE", "HISPANIC")) {
  if (v %in% names(dat)) dat[[v]] <- cat_to_numeric(dat[[v]])
}
dat_num <- dat[, sapply(dat, is.numeric)]
dat_scaled <- scale(dat_num)

# 4. tSNE降维
set.seed(42)
tsne_out <- Rtsne(as.matrix(dat_scaled), dims = 2, perplexity = 30, verbose = TRUE, max_iter = 1000)

# 5. KMeans聚类
k <- 3
kmeans_res <- kmeans(tsne_out$Y, centers = k, nstart = 20)
clusters <- as.factor(kmeans_res$cluster)

# 6. 汇总绘图数据
tsne_df <- data.frame(
  tSNE1 = tsne_out$Y[, 1],
  tSNE2 = tsne_out$Y[, 2],
  Cluster = clusters,
  DIAGNOSIS = if ("DIAGNOSIS" %in% names(complete_df)) complete_df$DIAGNOSIS else NA
)

# 7. 用诊断分色可视化
ggplot(tsne_df, aes(x = tSNE1, y = tSNE2, color = DIAGNOSIS)) +
  geom_point(size = 2, alpha = 0.8) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal(base_size = 14) +
  labs(title = "tSNE + KMeans (Colored by DIAGNOSIS)", color = "Diagnosis")


```



# concordance index 
```{r}

# Create a binary risk group based on median risk score
test_data$risk_group <- ifelse(test_data$risk_score > median(test_data$risk_score), "High", "Low")

# Plot Kaplan-Meier curves for high and low risk groups
library(survminer)
km_fit <- survfit(Surv(time, event) ~ risk_group, data = test_data)

# Visualize the survival curves
ggsurvplot(km_fit, data = test_data, pval = TRUE,
           risk.table = TRUE, # Show risk table
           title = "Kaplan-Meier Curves for High and Low Risk Groups")


```
```{r}
# Install and load timeROC if not already installed
if (!requireNamespace("timeROC", quietly = TRUE)) install.packages("timeROC")
library(timeROC)

# Define time points for ROC evaluation (e.g., 1 year, 2 years)
times <- c(1, 2) * 365.25  # Convert years to days

# Compute time-dependent ROC
roc <- timeROC(T = test_data$time, 
               delta = test_data$event, 
               marker = test_data$risk_score, 
               cause = 1, 
               times = times)

# Plot time-dependent ROC curve
plot(roc, time = 1, title = "Time-Dependent ROC at 1 Year")
plot(roc, time = 2, title = "Time-Dependent ROC at 2 Years")

```


# Initial overview table, BIOCARD

```{r}
get_src_table(path = "BIOCARD Demonstration")
```

```{r}
BIOCARD_table =get_src_table(path = "BIOCARD Demonstration",
              ID_usr_list = c("SUBJECT_ID"),
              DATE_usr_list = c("VISITDATE","DIAGDATE","date"),
              IS_overlap_list = c("FALSE"),
              WINDOW_list = c(366))

BIOCARD_table
```

```{r}
plot_files(path = "BIOCARD Demonstration", dict_src = BIOCARD_table, study_type = "BIOCARD",date_type = "Date") 
```


```{r}
Biocard_merged = ad_merge(path = "BIOCARD Demonstration",DATE_type = "Date",timeline_file = "BIOCARD_DiagnosisData_2021.11.01",dict_src = BIOCARD_table)

complete_output = review_complete(Biocard_merged,check_cols = c("LogMem1_B","LogMem2_B","DIAGNOSIS","DOB","RACE","AB40","AB42"))

#complete_output$plot

Biocard_merged$analysis_data
```


```{r}
Biocard_merged = ad_merge(path = "BIOCARD Demonstration",DATE_type = "Date",timeline_file = "BIOCARD_DiagnosisData_2021.11.01",dict_src = BIOCARD_table)


Biocard_merged$analysis_data$DIAGNOSIS
complete_output = review_complete(Biocard_merged,check_cols = c("LogMem1_B","LogMem2_B","DIAGNOSIS","DOB","RACE","AB40","AB42"))

complete_output

```


# Example with ADNI data

```{r}
get_src_table(path = "ADNI Demonstration")
```

```{r}
library(dplyr)


ADNI_table = get_src_table(path = "ADNI Demonstration",
                           ID_usr_list = c("RID"),
                           DATE_usr_list = c("EXAMDATE","VISDATE"),
                           non_longitudinal_list = c("APOERES_ADNI_1_2_3"),
                           IS_overlap_list = c("FALSE","FALSE","FALSE","TRUE","FALSE","FALSE","FALSE","FALSE"),
                           WINDOW_list = c(366,366,366,1830,366,366,366,366))

ADNI_table

plot_files(path = "ADNI Demonstration", dict_src = ADNI_table, study_type = "ADNI",date_type = "Date") 

ADNI_merged = ad_merge(path = "ADNI_Demonstration",
DATE_type = "Date",
timeline_file = "DXSUM",
dict_src = ADNI_table)
# 
complete_ADNI = review_complete(ADNI_merged, check_cols = c("PTGENDER","PTEDUCAT","N1M", "N2M", "N3M", "N4M", "R1M", "R2M", "R3M", "MIFR1M", "MIFR2M", "MIFR3M", "MDFR1M", "MTranM", "MDuraM","GENOTYPE","DIAGNOSIS","ST29SV","ST88SV"))
data = complete_ADNI$complete_df

complete_ADNI$plot

ADNI_merged$analysis_data

ADNI_Cognitive

# ADNI_merged$hold_data %>% distinct(ST153SV.dup)
# 
# UCSFFSX51_ADNI_1_GO_2$ST88SV
# 
# ADNI_merged$hold_data$ST153SV.dup

# ADNI_merged$hold_data 
# 
# ADNI_merged$hold_data_add
# 
# UCSFFSX6_ADNI_3 %>% filter(RID == 1016)

# Load necessary library
library(dplyr)

# Read the datasets
img_data <- read.csv("/Users/shijia.zhang/Downloads/df_first_folds.csv")

# Load necessary library
library(dplyr)

# Compute Sex distribution by DIAGNOSIS
sex_distribution <- img_data %>%
  group_by(DIAGNOSIS, Sex) %>%
  summarise(Count = n(), .groups = "drop") %>%
  mutate(Percentage = (Count / sum(Count)) * 100)

# Compute Age statistics by DIAGNOSIS
age_statistics <- img_data %>%
  group_by(DIAGNOSIS) %>%
  summarise(
    Mean_Age = mean(Age, na.rm = TRUE),
    Median_Age = median(Age, na.rm = TRUE),
    SD_Age = sd(Age, na.rm = TRUE),
    Min_Age = min(Age, na.rm = TRUE),
    Max_Age = max(Age, na.rm = TRUE),
    Count = n(),
    .groups = "drop"
  )

# Print results
print("Sex Distribution by Diagnosis")
print(sex_distribution)

print("Age Statistics by Diagnosis")
print(age_statistics)

library(dplyr)
all_image = read.csv("/Users/shijia.zhang/Downloads/ADNI_screening_baseline_w_csf_data.csv")

all_image %>% distinct(Subject,.keep_all = TRUE)%>%
  group_by(Group, Sex) %>%
  summarise(Count = n(), .groups = "drop") %>%
  mutate(Percentage = (Count / sum(Count)) * 100)

all_image %>% distinct(Subject,.keep_all = TRUE)%>%
  group_by(Group) %>%
  summarise(
    Mean_Age = mean(Age, na.rm = TRUE),
    Median_Age = median(Age, na.rm = TRUE),
    SD_Age = sd(Age, na.rm = TRUE),
    Min_Age = min(Age, na.rm = TRUE),
    Max_Age = max(Age, na.rm = TRUE),
    Count = n(),
    .groups = "drop"
  )



all_image %>% filter(Image.Data.ID %in% img_data$Image.ID) %>% distinct(Subject)
```

```{r}
print(age_statistics)
```

```{r}
library(dplyr)
library(ADMerge)

ADNI_table = get_src_table(path = "ami2_files",
                           ID_usr_list = c("PTID","group_id"),
                           DATE_usr_list = c("VISDATE","Acq.Date"),
                           IS_overlap_list = c("FALSE"),
                           WINDOW_list = c(366))

ADNI_table

plot_files(path = "ami2_files", dict_src = ADNI_table, study_type = "ADNI",date_type = "Date") 

df_first_folds

ADNI_merged = ad_merge(path = "ami2_files",
DATE_type = "Date",
timeline_file = "df_first_folds",
dict_src = ADNI_table)

merged_folds = ADNI_merged$analysis_data %>% select(c("ID_merged","Date_timeline","Image.ID","Sex","Age","DIAGNOSIS","linear_registered_path","non_linear_registered_path","syn_jacobian","fold","CDGLOBAL","MMSCORE"))

merged_folds


summary_stats <- merged_folds %>%
  group_by(DIAGNOSIS) %>%
  summarise(
    n = n(),
    avg_Age = mean(Age, na.rm = TRUE),
    avg_MMSCORE = mean(MMSCORE, na.rm = TRUE),
    avg_global = mean(CDGLOBAL, na.rm = TRUE),
    male_count = sum(Sex == "M", na.rm = TRUE),
    female_count = sum(Sex == "F", na.rm = TRUE)
  )

print(summary_stats)

filtered_cases <- merged_folds %>%
  filter(
    (DIAGNOSIS == 1 & CDGLOBAL != 0) |
    (DIAGNOSIS == 2 & CDGLOBAL != 0.5) |
    (DIAGNOSIS == 3 & CDGLOBAL < 1)
  )
# To view the filtered cases:
filtered_cases %>% select(Image.ID,DIAGNOSIS,CDGLOBAL)



merged_folds %>% select(Image.ID,DIAGNOSIS,CDGLOBAL,MMSCORE)
```

```{r}
adni_screening = read.csv("/Users/shijia.zhang/Desktop/adni_screening.csv")

adni_screening_unique <- adni_screening[!duplicated(adni_screening$Subject, fromLast = TRUE), ]


ADNI_table = get_src_table(path = "aim2_sc",
                           ID_usr_list = c("PTID","Subject"),
                           DATE_usr_list = c("VISDATE","Acq.Date"),
                           IS_overlap_list = c("FALSE"),
                           WINDOW_list = c(366))

sc_data %>% filter(Image.Data.ID %in% adni_screening$Image.Data.ID) 


ADNI_merged = ad_merge(path = "aim2_sc",
DATE_type = "Date",
timeline_file = "adni_screening",
dict_src = ADNI_table)

analysis_data = ADNI_merged$analysis_data

analysis_data = analysis_data %>% select(ID_merged,Date_timeline,Image.Data.ID,Group,Sex,Age,CDGLOBAL,MMSCORE)

summary_stats <- analysis_data %>%
  group_by(Group) %>%
  summarise(
    n = n(),
    avg_Age = mean(Age, na.rm = TRUE),
    avg_CDGLOBAL = mean(CDGLOBAL, na.rm = TRUE),
    avg_MMSCORE = mean(MMSCORE, na.rm = TRUE),
    male_count = sum(Sex == "M", na.rm = TRUE),
    female_count = sum(Sex == "F", na.rm = TRUE)
  )

print(summary_stats)


filtered_cases <- analysis_data %>%
  filter(
    (Group == "CN" & CDGLOBAL != 0) |
    (Group == "MCI" & CDGLOBAL != 0.5) |
    (Group == "AD" & CDGLOBAL < 1)
  )
# To view the filtered cases:
filtered_cases %>% select(ID_merged,Group,CDGLOBAL)


summary_stats
analysis_data
```



```{r}
baseline_all = read.csv("/Users/shijia.zhang/Downloads/ADNI_screening_baseline_w_csf_data_365_02162024 (2).csv")



img_data <- read.csv("/Users/shijia.zhang/Downloads/df_first_folds.csv")

# Load necessary library
library(dplyr)

# Ensure baseline_all has unique Subject-dx pairs
# Load necessary library
library(dplyr)

# Ensure baseline_all has unique Subject-dx pairs
baseline_unique <- baseline_all %>%
  distinct(Subject, dx, .keep_all = TRUE)

# Merge img_data and baseline_all by Subject (group_id in img_data)
merged_data <- img_data %>%
  select(group_id, DIAGNOSIS) %>%  # Keep relevant columns
  inner_join(baseline_unique, by = c("group_id" = "Subject"))

# Check how many match and mismatch
match_count <- merged_data %>%
  filter(DIAGNOSIS == dx) %>%
  nrow()

mismatch_count <- merged_data %>%
  filter(DIAGNOSIS != dx) %>%
  nrow()

# Identify mismatched cases
mismatched_cases <- merged_data %>%
  filter(DIAGNOSIS != dx)

# Print results
print(paste("Number of matches:", match_count))
print(paste("Number of mismatches:", mismatch_count))

# Print mismatched dx values
print("Mismatched dx values:")
print(mismatched_cases$dx)

# Print mismatched DIAGNOSIS values
print("Mismatched DIAGNOSIS values:")
print(mismatched_cases$DIAGNOSIS)


```


```{r}
library(dplyr)
library(caret)
library(randomForest)
library(e1071)
library(dplyr)
library(caret)
library(randomForest)
library(pROC)
data
```

```{r}
# Extract the complete dataset
data <- complete_ADNI$complete_df
# Remove all visits with DIAGNOSIS == 3
data <- data %>% filter(DIAGNOSIS != 3)

# Get IDs of patients who transitioned to MCI
mci_patients <- data %>%
  filter(DIAGNOSIS == 2) %>%
  pull(ID_merged) %>%
  unique()

# For each MCI patient, find the first MCI diagnosis date
first_mci_dates <- data %>%
  filter(ID_merged %in% mci_patients, DIAGNOSIS == 2) %>%
  group_by(ID_merged) %>%
  summarize(first_mci_date = min(Date_timeline))


# Merge first MCI dates back into data
data <- data %>%
  left_join(first_mci_dates, by = "ID_merged")

# Select visits before the first MCI diagnosis
pre_mci_data <- data %>%
  filter(DIAGNOSIS == 1, Date_timeline < first_mci_date)

# Get the last visit before MCI for each patient
positive_cases <- pre_mci_data %>%
  group_by(ID_merged) %>%
  filter(Date_timeline == max(Date_timeline)) %>%
  ungroup()

# Get IDs of control patients
control_patients <- data %>%
  group_by(ID_merged) %>%
  filter(all(DIAGNOSIS == 1)) %>%
  pull(ID_merged) %>%
  unique()

# Get the last visit for control patients
control_data <- data %>%
  filter(ID_merged %in% control_patients) %>%
  group_by(ID_merged) %>%
  filter(Date_timeline == max(Date_timeline)) %>%
  ungroup()

num_positive <- nrow(positive_cases)
set.seed(123)  # For reproducibility
control_sample <- control_data %>%
  sample_n(num_positive * 2)

positive_cases <- positive_cases %>% mutate(label = 1)
control_sample <- control_sample %>% mutate(label = 0)


predictor_vars <- c("N1M", "N2M", "N3M", "N4M", "R1M", "R2M", "R3M",
                    "MIFR1M", "MIFR2M", "MIFR3M", "MDFR1M", "MTranM",
                    "MDuraM", "GENOTYPE", "ST29SV", "ST88SV", "PTGENDER", "PTEDUCAT")

final_data <- bind_rows(positive_cases, control_sample)

final_data <- final_data %>%
  select(ID_merged, all_of(predictor_vars), label)

final_data$GENOTYPE <- as.factor(final_data$GENOTYPE)
final_data$PTGENDER <- as.factor(final_data$PTGENDER)
final_data$label <- as.factor(final_data$label)




```

```{r}

# Load necessary libraries
library(dplyr)
library(caret)
library(pROC)
library(randomForest)
library(e1071)
library(gbm)

# Assume 'final_data' is available from previous steps
# Convert label to factor with appropriate levels
final_data$label <- factor(final_data$label, levels = c(0, 1), labels = c("Control", "MCI"))

# Set up cross-validation control
set.seed(123)  # For reproducibility
cv_control <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  savePredictions = "final"
)

### **Model 1: Random Forest**

# Train Random Forest model with cross-validation
set.seed(456)
rf_cv_model <- train(
  label ~ .,
  data = final_data[, -1],  # Exclude ID_merged column
  method = "rf",
  trControl = cv_control,
  metric = "ROC",
  tuneLength = 5
)

# Extract best ROC AUC
rf_best <- rf_cv_model$results[which.max(rf_cv_model$results$ROC), ]
rf_best$Model <- "Random Forest"

### **Model 2: Support Vector Machine (SVM)**

# Train SVM model with cross-validation
set.seed(456)
svm_cv_model <- train(
  label ~ .,
  data = final_data[, -1],
  method = "svmRadial",
  trControl = cv_control,
  metric = "ROC",
  tuneLength = 5
)

# Extract best ROC AUC
svm_best <- svm_cv_model$results[which.max(svm_cv_model$results$ROC), ]
svm_best$Model <- "SVM"

### **Model 3: Logistic Regression**

# Train Logistic Regression model with cross-validation
set.seed(456)
glm_cv_model <- train(
  label ~ .,
  data = final_data[, -1],
  method = "glm",
  family = binomial,
  trControl = cv_control,
  metric = "ROC"
)

# Extract ROC AUC
glm_best <- glm_cv_model$results
glm_best$Model <- "Logistic Regression"

### **Model 4: Gradient Boosting Machine (GBM)**

# Train GBM model with cross-validation
set.seed(456)
gbm_cv_model <- train(
  label ~ .,
  data = final_data[, -1],
  method = "gbm",
  trControl = cv_control,
  metric = "ROC",
  verbose = FALSE,
  tuneLength = 5
)

# Extract best ROC AUC
gbm_best <- gbm_cv_model$results[which.max(gbm_cv_model$results$ROC), ]
gbm_best$Model <- "GBM"

### **Compile Best Results**

# Select relevant columns and bind the best results together
best_results <- bind_rows(
  rf_best %>% select(Model, ROC, Sens, Spec,ROCSD,SpecSD),
  svm_best %>% select(Model, ROC, Sens, Spec,ROCSD,SpecSD),
  glm_best %>% select(Model, ROC, Sens, Spec,ROCSD,SpecSD),
  gbm_best %>% select(Model, ROC, Sens, Spec,ROCSD,SpecSD)
)

print("Best Cross-Validated Performance Metrics:")
print(best_results)

### **Plot ROC Curves Together**

# Function to extract ROC data for plotting
get_roc_data <- function(model, model_name) {
  preds <- model$pred
  if ("mtry" %in% colnames(preds)) {
    # For Random Forest, filter predictions for best mtry
    best_param <- model$bestTune$mtry
    preds <- preds[preds$mtry == best_param, ]
  } else if ("C" %in% colnames(preds)) {
    # For SVM, filter predictions for best cost parameter
    best_param <- model$bestTune$C
    preds <- preds[preds$C == best_param, ]
  } else if ("n.trees" %in% colnames(preds)) {
    # For GBM, filter predictions for best n.trees
    best_param <- model$bestTune$n.trees
    preds <- preds[preds$n.trees == best_param, ]
  }
  roc_obj <- roc(response = preds$obs, predictor = preds$MCI, levels = rev(levels(preds$obs)))
  roc_df <- data.frame(
    FalsePositiveRate = 1 - roc_obj$specificities,
    TruePositiveRate = roc_obj$sensitivities,
    Model = model_name
  )
  return(roc_df)
}

# Get ROC data for each model
roc_rf <- get_roc_data(rf_cv_model, "Random Forest")
roc_svm <- get_roc_data(svm_cv_model, "SVM")
roc_glm <- get_roc_data(glm_cv_model, "Logistic Regression")
roc_gbm <- get_roc_data(gbm_cv_model, "GBM")

# Combine ROC data
roc_data <- bind_rows(roc_rf, roc_svm, roc_glm, roc_gbm)

# Plot ROC curves
library(ggplot2)
ggplot(roc_data, aes(x = FalsePositiveRate, y = TruePositiveRate, color = Model)) +
  geom_line(size = 1) +
  geom_abline(linetype = "dashed") +
  theme_minimal() +
  labs(title = "ROC Curves for Different Models", x = "False Positive Rate", y = "True Positive Rate") +
  theme(legend.position = "bottom")


```

```{r}
data %>% filter(ID_merged == 22) %>% select(Date_timeline,DIAGNOSIS)

final_data$label <- factor(final_data$label, levels = c(0, 1), labels = c("Control", "MCI"))
best_results %>% kable() %>% kable_styling(latex_options = c("striped", "hold_position"))
```

```{r}
final_data
```




# ADNI example

```{r}
ADNI_table = get_src_table(path = "ADNI Demonstration",
                           ID_usr_list = c("RID"),
                           DATE_usr_list = c("VISDATE","EXAMDATE","VISDATE","EXAMDATE"),
                           non_longitudinal_list = c("APOERES_ADNI_1_2_3"),
                           IS_overlap_list = c("FALSE","FALSE","FALSE","TRUE","FALSE","FALSE"),
                           WINDOW_list = c(366,366,366,1830,366,366))

ADNI_table

plot_files(path = "ADNI Demonstration", dict_src = ADNI_table, study_type = "ADNI",date_type = "Date") 

ADNI_merged = ad_merge(path = "ADNI_Demonstration",
DATE_type = "Date",
timeline_file = "DXSUM",
dict_src = ADNI_table)

ADNI_merged$analysis_data %>% filter(PHASE == "ADNI3") 

ADNI_merged$analysis_data$MMSCORE

ADNI_merged$analysis_data

complete_ADNI = review_complete(ADNI_merged, check_cols = c("N1M", "N2M", "N3M", "N4M", "R1M", "R2M", "R3M", "MIFR1M", "MIFR2M", "MIFR3M", "MDFR1M", "MTranM", "MDuraM","GENOTYPE","DIAGNOSIS","ST29SV","ST88SV"))

complete_ADNI$complete_df %>% filter(DIAGNOSIS == 1)

ADNI_
```

```{r}


library(dplyr)

ADNI_table = get_src_table(path = "ADNI Demonstration",
                           ID_usr_list = c("RID"),
                           DATE_usr_list = c("VISDATE","EXAMDATE","VISDATE","EXAMDATE","EXAMDATE"),
                           non_longitudinal_list = c("APOERES_ADNI_1_2_3"),
                           IS_overlap_list = c("FALSE","FALSE","FALSE","TRUE","FALSE","FALSE"),
                           WINDOW_list = c(366))

plot_files(path = "ADNI Demonstration", dict_src = ADNI_table, study_type = "ADNI",date_type = "Date") 

ADNI_merged = ad_merge(path = "ADNI_Demonstration",
DATE_type = "Date",
timeline_file = "DXSUM",
dict_src = ADNI_table)

```

```{r}
# Load necessary library
library(dplyr)

# Create the first data frame (df1)
df1 <- data.frame(
  ID = c(1, 2, 3, 4),
  Value1 = c(NA, 20, 30, NA),
  Value2 = c(100, NA, 300, 400),
  stringsAsFactors = FALSE
)

# Create the second data frame (df2)
df2 <- data.frame(
  ID = c(1, 2, 3, 4),
  Value1 = c(10, 25, NA, 40),
  Value2 = c(NA, 250, 350, 450),
  stringsAsFactors = FALSE
)

# View the data frames
print("df1:")
print(df1)

print("df2:")
print(df2)

# Perform a left join on 'ID'
df_joined <- df1 %>%
  left_join(df2, by = "ID", suffix = c("", ".df2"))

# View the joined data frame
print("Joined Data Frame:")
print(df_joined)

# Use coalesce to replace NA values in df1 columns with values from df2
df_joined <- df_joined %>%
  mutate(
    Value1 = coalesce(Value1, Value1.df2),
    Value2 = coalesce(Value2, Value2.df2)
  ) %>%
  # Remove the .df2 columns
  select(-Value1.df2, -Value2.df2)

# View the final data frame
print("Final Data Frame after coalesce:")
print(df_joined)

```
```{r}
# Load necessary library
library(dplyr)

# Create the first data frame (df1)
df1 <- data.frame(
  ID = c(1, 2, 3, 4),
  Value1 = c(NA, 20, 30, NA),
  Value2 = c(100, NA, 300, 400),
  stringsAsFactors = FALSE
)

# Create the second data frame (df2)
df2 <- data.frame(
  ID = c(1, 2, 3, 4),
  Value1 = c(10, 25, NA, 40),
  Value2 = c(NA, 250, 350, 450),
  stringsAsFactors = FALSE
)

# View the data frames
print("df1:")
print(df1)

print("df2:")
print(df2)

# Perform a left join on 'ID'
df_joined <- df1 %>%
  left_join(df2, by = "ID", suffix = c("", ".df2"))

# View the joined data frame
print("Joined Data Frame:")
print(df_joined)

# Use mutate(across(everything(), ...)) to coalesce columns
df_joined <- df_joined %>%
  mutate(across(everything(), ~ {
    dup_col <- paste0(cur_column(), ".df2")
    if (dup_col %in% names(.)) {
      coalesce(.x, .[[dup_col]])
    } else {
      .x
    }
  })) %>%
  select(-ends_with(".df2"))

# View the final data frame
print("Final Data Frame after coalesce:")
print(df_joined)

```

```{r}
# Load necessary library
library(dplyr)

# Create the first data frame (df1)
df1 <- data.frame(
  ID = c(1, 2, 3, 4),
  Value1 = c(NA, 20, 30, NA),
  Value2 = c(100, NA, 300, 400),
  stringsAsFactors = FALSE
)
print(df1)

# Create the second data frame (df2)
df2 <- data.frame(
  ID = c(1, 2, 3, 4),
  Value1 = c(10, 25, NA, 40),
  Value2 = c(NA, 250, 350, 450),
  stringsAsFactors = FALSE
)
print(df2)

# Perform a left join on 'ID'
df_joined <- df1 %>%
  left_join(df2, by = "ID", suffix = c("", ".df2"))

print(df_joined)

# Identify duplicate columns
dup_columns <- names(df_joined)[grepl("\\.df2$", names(df_joined))]
orig_columns <- sub("\\.df2$", "", dup_columns)

# Replace NA values in original columns with values from the duplicate columns
for (col in orig_columns) {
  dup_col <- paste0(col, ".df2")
  df_joined[[col]] <- coalesce(df_joined[[col]], df_joined[[dup_col]])
}

# Remove the duplicate columns
df_joined <- df_joined %>% select(-ends_with(".df2"))

# View the final data frame
print("Final Data Frame after coalesce:")
print(df_joined)

```
```{r}
library(tidyverse)
y <- c(1, 2, NA, NA, 5)
z <- c(NA, NA, 3, 4, 5)
coalesce(y, z)
```

