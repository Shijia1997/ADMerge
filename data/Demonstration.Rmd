---
title: "Vignette"
author: "Shijia Zhang"
date: "2024-08-28"
output: html_document
---

```{r}
library(devtools)
install_github("Shijia1997/ADMerge",force = TRUE)

library(ADMerge)
# library(dplyr)
library(knitr)
# library(readxl)
library(kableExtra)
```

# updated

```{r}
library(dplyr)
BIOCARD_table =get_src_table(path = "BIOCARD Demonstration",
              ID_usr_list = c("SUBJECT_ID"),
              DATE_usr_list = c("VISITDATE","DIAGDATE","date"),
              IS_overlap_list = c("FALSE"),
              WINDOW_list = c(366))

plot_files(path = "BIOCARD Demonstration", dict_src = BIOCARD_table, study_type = "BIOCARD",date_type = "Date") 

Biocard_merged = ad_merge(path = "BIOCARD Demonstration",DATE_type = "Date",timeline_file = "BIOCARD_DiagnosisData_2021.11.01",dict_src = BIOCARD_table)

complete_output = review_complete(Biocard_merged,check_cols = c("C1204A","C1204B","DIAGNOSIS","DOB","RACE","AB40","AB42"))

data = complete_output$complete_df

complete_output$plot

data = data %>% mutate(cognitive_impairment_conditions = case_when(DIAGNOSIS == "NORMAL" ~0,
                                                                   TRUE ~ 1))
# Prepare the data
# Ensure Date columns are in Date format at the outset
cox_df <- data %>%
  group_by(ID_merged) %>%
  summarize(
    # Use if_else to preserve Date type for first_impairment_date
    first_impairment_date = if_else(
      any(cognitive_impairment_conditions == 1),
      min(Date_timeline[cognitive_impairment_conditions == 1], na.rm = TRUE),
      as.Date(NA)  # Ensure NA is treated as Date type
    ),
    # Calculate last visit date and baseline date
    last_visit_date = max(Date_timeline, na.rm = TRUE),
    baseline_date = min(Date_timeline, na.rm = TRUE),
    # Define event as 1 if any impairment was observed
    event = if_else(any(cognitive_impairment_conditions == 1), 1, 0),
    # Retrieve additional columns from the first encounter
    C1204A = C1204A[which.min(Date_timeline)],
    C1204B = C1204B[which.min(Date_timeline)],
    RACE = RACE[which.min(Date_timeline)],
    AB40 = AB40[which.min(Date_timeline)],
    AB42 = AB42[which.min(Date_timeline)]
  ) %>%
  mutate(
    # Define tstart as 0 and tstop based on event status
    tstart = 0,
    tstop = if_else(
      event == 1,
      as.numeric((first_impairment_date - baseline_date) / 365.25),  # Time to event
      as.numeric((last_visit_date - baseline_date) / 365.25)  # Time to censoring
    )
  ) %>%
  # Retain rows where tstop is not zero and select required columns
  filter(tstop != 0) %>%
  select(ID_merged, tstart, tstop, event, C1204A, C1204B, RACE, AB40,AB42)


cox_df$event <- as.factor(cox_df$event)
cox_df$event <- droplevels(factor(cox_df$event, levels = c(0, 1)))


library(DMwR)
# Ensure the dataset has no unused levels and is formatted properly
cox_df <- droplevels(cox_df)

cox_df <- as.data.frame(cox_df)

cox_df <- cox_df %>% select(-c(ID_merged))

# Applying SMOTE on `event` column
smoted_data <- SMOTE(event ~ ., data = cox_df, perc.over = 2000, perc.under = 150)

library(survival)
library(caret)

# Set a seed for reproducibility
set.seed(123)

# Split data into training (80%) and testing (20%) sets
train_index <- createDataPartition(smoted_data$event, p = 0.8, list = FALSE)
train_data <- smoted_data[train_index, ]
test_data <- smoted_data[-train_index, ]

train_data$time = train_data$tstop
test_data$time = test_data$tstop

train_data <- train_data %>% select(-tstart)
test_data <- test_data %>% select(-tstart)

train_data$event <- as.numeric(as.character(train_data$event))
test_data$event <- as.numeric(as.character(test_data$event))


cox_model <- coxph(Surv(time, event) ~ C1204A + C1204B + RACE + AB40 + AB42, data = train_data)

test_data$risk_score <- predict(cox_model, newdata = test_data, type = "risk")


cox_model %>% gtsummary::tbl_regression(exp =TRUE)


```
# concordance index 
```{r}

# Create a binary risk group based on median risk score
test_data$risk_group <- ifelse(test_data$risk_score > median(test_data$risk_score), "High", "Low")

# Plot Kaplan-Meier curves for high and low risk groups
library(survminer)
km_fit <- survfit(Surv(time, event) ~ risk_group, data = test_data)

# Visualize the survival curves
ggsurvplot(km_fit, data = test_data, pval = TRUE,
           risk.table = TRUE, # Show risk table
           title = "Kaplan-Meier Curves for High and Low Risk Groups")


```
```{r}
# Install and load timeROC if not already installed
if (!requireNamespace("timeROC", quietly = TRUE)) install.packages("timeROC")
library(timeROC)

# Define time points for ROC evaluation (e.g., 1 year, 2 years)
times <- c(1, 2) * 365.25  # Convert years to days

# Compute time-dependent ROC
roc <- timeROC(T = test_data$time, 
               delta = test_data$event, 
               marker = test_data$risk_score, 
               cause = 1, 
               times = times)

# Plot time-dependent ROC curve
plot(roc, time = 1, title = "Time-Dependent ROC at 1 Year")
plot(roc, time = 2, title = "Time-Dependent ROC at 2 Years")

```


# Initial overview table, BIOCARD

```{r}
get_src_table(path = "BIOCARD Demonstration")
```

```{r}
BIOCARD_table =get_src_table(path = "BIOCARD Demonstration",
              ID_usr_list = c("SUBJECT_ID"),
              DATE_usr_list = c("VISITDATE","DIAGDATE","date"),
              IS_overlap_list = c("FALSE"),
              WINDOW_list = c(366))

BIOCARD_table
```

```{r}
plot_files(path = "BIOCARD Demonstration", dict_src = BIOCARD_table, study_type = "BIOCARD",date_type = "Date") 
```


```{r}
Biocard_merged = ad_merge(path = "BIOCARD Demonstration",DATE_type = "Date",timeline_file = "BIOCARD_DiagnosisData_2021.11.01",dict_src = BIOCARD_table)

complete_output = review_complete(Biocard_merged,check_cols = c("LogMem1_B","LogMem2_B","DIAGNOSIS","DOB","RACE","AB40","AB42"))

#complete_output$plot

Biocard_merged$analysis_data
```


```{r}
Biocard_merged = ad_merge(path = "BIOCARD Demonstration",DATE_type = "Date",timeline_file = "BIOCARD_DiagnosisData_2021.11.01",dict_src = BIOCARD_table)


Biocard_merged$analysis_data$DIAGNOSIS
complete_output = review_complete(Biocard_merged,check_cols = c("LogMem1_B","LogMem2_B","DIAGNOSIS","DOB","RACE","AB40","AB42"))

complete_output

```


# Example with ADNI data

```{r}
get_src_table(path = "ADNI Demonstration",)
```
```{r}
library(dplyr)


ADNI_table = get_src_table(path = "ADNI Demonstration",
                           ID_usr_list = c("RID"),
                           DATE_usr_list = c("EXAMDATE","VISDATE"),
                           non_longitudinal_list = c("APOERES_ADNI_1_2_3"),
                           IS_overlap_list = c("FALSE","FALSE","FALSE","TRUE","FALSE","FALSE","FALSE","FALSE"),
                           WINDOW_list = c(366,366,366,1830,366,366,366,366))

ADNI_table

plot_files(path = "ADNI Demonstration", dict_src = ADNI_table, study_type = "ADNI",date_type = "Date") 

ADNI_merged = ad_merge(path = "ADNI_Demonstration",
DATE_type = "Date",
timeline_file = "DXSUM",
dict_src = ADNI_table)
# 
ADNI_merged$analysis_data %>% filter(PHASE == "ADNI3") %>% filter(!is.na(ST88SV))

# ADNI_merged$hold_data %>% distinct(ST153SV.dup)
# 
# UCSFFSX51_ADNI_1_GO_2$ST88SV
# 
# ADNI_merged$hold_data$ST153SV.dup

# ADNI_merged$hold_data 
# 
# ADNI_merged$hold_data_add
# 
# UCSFFSX6_ADNI_3 %>% filter(RID == 1016)

UCSFFSX6_ADNI_3 %>% filter(RID == 21)
```
# ADNI example

```{r}
ADNI_table = get_src_table(path = "ADNI Demonstration",
                           ID_usr_list = c("RID"),
                           DATE_usr_list = c("VISDATE","EXAMDATE","VISDATE","EXAMDATE"),
                           non_longitudinal_list = c("APOERES_ADNI_1_2_3"),
                           IS_overlap_list = c("FALSE","FALSE","FALSE","TRUE","FALSE","FALSE"),
                           WINDOW_list = c(366,366,366,732,366,366))

ADNI_table

plot_files(path = "ADNI Demonstration", dict_src = ADNI_table, study_type = "ADNI",date_type = "Date") 

ADNI_merged = ad_merge(path = "ADNI_Demonstration",
DATE_type = "Date",
timeline_file = "DXSUM",
dict_src = ADNI_table)

ADNI_merged$analysis_data %>% filter(PHASE == "ADNI3") 

ADNI_merged$analysis_data$MMSCORE

MMSCORE

review_complete(ADNI_merged, check_cols = c("MMSCORE","GENOTYPE","DIAGNOSIS","ST29SV","ST88SV"))
```

```{r}
source("/Users/shijia.zhang/Desktop/ADNI/ADMerge/R/adm_main.R")
source("/Users/shijia.zhang/Desktop/ADNI/ADMerge/R/adm_helper.R")


library(dplyr)

ADNI_table = get_src_table(path = "ADNI Demonstration",
                           ID_usr_list = c("RID"),
                           DATE_usr_list = c("VISDATE","EXAMDATE","VISDATE","EXAMDATE","EXAMDATE"),
                           non_longitudinal_list = c("APOERES_ADNI_1_2_3"),
                           IS_overlap_list = c("FALSE","FALSE","FALSE","TRUE","FALSE","FALSE"),
                           WINDOW_list = c(366))

plot_files(path = "ADNI Demonstration", dict_src = ADNI_table, study_type = "ADNI",date_type = "Date") 

ADNI_merged = ad_merge(path = "ADNI_Demonstration",
DATE_type = "Date",
timeline_file = "DXSUM",
dict_src = ADNI_table)

```

```{r}
# Load necessary library
library(dplyr)

# Create the first data frame (df1)
df1 <- data.frame(
  ID = c(1, 2, 3, 4),
  Value1 = c(NA, 20, 30, NA),
  Value2 = c(100, NA, 300, 400),
  stringsAsFactors = FALSE
)

# Create the second data frame (df2)
df2 <- data.frame(
  ID = c(1, 2, 3, 4),
  Value1 = c(10, 25, NA, 40),
  Value2 = c(NA, 250, 350, 450),
  stringsAsFactors = FALSE
)

# View the data frames
print("df1:")
print(df1)

print("df2:")
print(df2)

# Perform a left join on 'ID'
df_joined <- df1 %>%
  left_join(df2, by = "ID", suffix = c("", ".df2"))

# View the joined data frame
print("Joined Data Frame:")
print(df_joined)

# Use coalesce to replace NA values in df1 columns with values from df2
df_joined <- df_joined %>%
  mutate(
    Value1 = coalesce(Value1, Value1.df2),
    Value2 = coalesce(Value2, Value2.df2)
  ) %>%
  # Remove the .df2 columns
  select(-Value1.df2, -Value2.df2)

# View the final data frame
print("Final Data Frame after coalesce:")
print(df_joined)

```
```{r}
# Load necessary library
library(dplyr)

# Create the first data frame (df1)
df1 <- data.frame(
  ID = c(1, 2, 3, 4),
  Value1 = c(NA, 20, 30, NA),
  Value2 = c(100, NA, 300, 400),
  stringsAsFactors = FALSE
)

# Create the second data frame (df2)
df2 <- data.frame(
  ID = c(1, 2, 3, 4),
  Value1 = c(10, 25, NA, 40),
  Value2 = c(NA, 250, 350, 450),
  stringsAsFactors = FALSE
)

# View the data frames
print("df1:")
print(df1)

print("df2:")
print(df2)

# Perform a left join on 'ID'
df_joined <- df1 %>%
  left_join(df2, by = "ID", suffix = c("", ".df2"))

# View the joined data frame
print("Joined Data Frame:")
print(df_joined)

# Use mutate(across(everything(), ...)) to coalesce columns
df_joined <- df_joined %>%
  mutate(across(everything(), ~ {
    dup_col <- paste0(cur_column(), ".df2")
    if (dup_col %in% names(.)) {
      coalesce(.x, .[[dup_col]])
    } else {
      .x
    }
  })) %>%
  select(-ends_with(".df2"))

# View the final data frame
print("Final Data Frame after coalesce:")
print(df_joined)

```

```{r}
# Load necessary library
library(dplyr)

# Create the first data frame (df1)
df1 <- data.frame(
  ID = c(1, 2, 3, 4),
  Value1 = c(NA, 20, 30, NA),
  Value2 = c(100, NA, 300, 400),
  stringsAsFactors = FALSE
)
print(df1)

# Create the second data frame (df2)
df2 <- data.frame(
  ID = c(1, 2, 3, 4),
  Value1 = c(10, 25, NA, 40),
  Value2 = c(NA, 250, 350, 450),
  stringsAsFactors = FALSE
)
print(df2)

# Perform a left join on 'ID'
df_joined <- df1 %>%
  left_join(df2, by = "ID", suffix = c("", ".df2"))

print(df_joined)

# Identify duplicate columns
dup_columns <- names(df_joined)[grepl("\\.df2$", names(df_joined))]
orig_columns <- sub("\\.df2$", "", dup_columns)

# Replace NA values in original columns with values from the duplicate columns
for (col in orig_columns) {
  dup_col <- paste0(col, ".df2")
  df_joined[[col]] <- coalesce(df_joined[[col]], df_joined[[dup_col]])
}

# Remove the duplicate columns
df_joined <- df_joined %>% select(-ends_with(".df2"))

# View the final data frame
print("Final Data Frame after coalesce:")
print(df_joined)

```

